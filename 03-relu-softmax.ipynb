{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - relu-softmax\n",
    "\n",
    "For more info about this code, follow:\n",
    "\n",
    "* https://www.tensorflow.org/get_started/mnist/pros : the section about softmax\n",
    "* http://www.ritchieng.com/machine-learning/deep-learning/tensorflow/deep-neural-nets/\n",
    "\n",
    "Before get into convnet implementation (that is the last modal we are going to implement) let's make a more complex neural network. \n",
    "\n",
    "We've been working on models that can be implemented just perfectly fine without tensorflow or neural networks, now let's do the real thing.\n",
    "\n",
    "We will implement a neural network with 1 hidden layer, firt relu then softmax (output). You can see a figure that describes this network bellow, let's do it!\n",
    "\n",
    "![Neural Network](http://www.extremetech.com/wp-content/uploads/2015/07/NeuralNetwork.png)\n",
    "Image from http://www.extremetech.com/wp-content/uploads/2015/07/NeuralNetwork.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# needed libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# mnist.train = 55,000 input data\n",
    "# mnist.test = 10,000 input data\n",
    "# mnist.validate = 5,000 input data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Relu and Softmax Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_nodes = 1024\n",
    "batch_size = 128 # sg, if we use all the data the trainning will take a lot of time\n",
    "\n",
    "# input\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "# --------- hidden layer (RELU) -------------\n",
    "\n",
    "# weight\n",
    "w1 = tf.Variable(tf.truncated_normal([784, num_nodes]))\n",
    "# bias\n",
    "b1 = tf.Variable(tf.zeros([num_nodes]))\n",
    "# test_data * w1 + b1\n",
    "y1 = tf.matmul(x, w1) + b1\n",
    "relu = tf.nn.relu(y1)\n",
    "\n",
    "# -------- output layer (sofmax) -------------\n",
    "\n",
    "# weight\n",
    "w2 = tf.Variable(tf.truncated_normal([num_nodes, 10]))\n",
    "# bias\n",
    "b2 = tf.Variable(tf.zeros([10]))\n",
    "# relu * w2 + b2\n",
    "y2 = tf.matmul(relu, w2) + b2\n",
    "sm = tf.nn.softmax(y2)\n",
    "\n",
    "# cross entropy (loss function)\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y2, labels=y_))\n",
    "\n",
    "# train step\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "# evaluating the model\n",
    "correct_prediction = tf.equal(tf.argmax(sm, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# init\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Accuracy: 95.1200008392 %\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3000\n",
    "with tf.Session() as session:\n",
    "    \n",
    "    session.run(init)\n",
    "    \n",
    "    # training\n",
    "    for step in xrange(num_steps):\n",
    "        # Generate a minibatch.\n",
    "        batch_data, batch_labels = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        error, ts, acc = session.run([loss, train_step, accuracy], \n",
    "                                     feed_dict={x: batch_data, y_: batch_labels})       \n",
    "    \n",
    "    # evaluating the model\n",
    "    acc = accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "\n",
    "    print 'Done!'\n",
    "    print 'Accuracy:', acc * 100, '%'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
