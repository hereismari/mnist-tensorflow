{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - convnet\n",
    "\n",
    "For more info about this code, follow:\n",
    "\n",
    "* https://www.tensorflow.org/get_started/mnist/pros\n",
    "* https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/convolutional_network.py\n",
    "* http://cv-tricks.com/tensorflow-tutorial/training-convolutional-neural-network-for-image-classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# needed libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# mnist.train = 55,000 input data\n",
    "# mnist.test = 10,000 input data\n",
    "# mnist.validate = 5,000 input data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Convnet with TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    # break simmetry\n",
    "    w = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(w)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    # avoid dead neurons\n",
    "    b = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(b)\n",
    "\n",
    "# pool\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# creates default conv layer\n",
    "def new_conv_layer(input, num_input_channels, filter_size, num_filters, use_pooling=True):\n",
    " \n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    " \n",
    "    weights = weight_variable(shape)\n",
    "    biases = bias_variable([num_filters])\n",
    " \n",
    "    # input: 4D tensor (normally: [num_inputs, width, height, depth])\n",
    "    # filter: 4d tensor we will learn and move in the image as defined\n",
    "    #         by strides.\n",
    "    #         (normally: [filter_size, filter_size, num_input_channels, num_filters])\n",
    "    # strides: [batch_stride x_stride y_stride depth_stride]\n",
    "    #           batch_stride = 1 (we don't want to skip images)\n",
    "    #           x_stride = move filter x positions\n",
    "    #           y_stride = move filter y positions\n",
    "    #           depth_stride = 1 (we don't want to skip any depth channel)\n",
    "    # padding: SAME, means we will 0 pad the image, so the output\n",
    "    #          will have the same dimension of the input\n",
    "    layer = tf.nn.relu(tf.nn.conv2d(input=input,\n",
    "                                    filter=weights,\n",
    "                                    strides=[1, 1, 1, 1],\n",
    "                                    padding='SAME') + biases)\n",
    "\n",
    "    if use_pooling: \n",
    "        return max_pool_2x2(layer), weights\n",
    "\n",
    "    return layer, weights\n",
    "\n",
    "def flatten_layer(layer):\n",
    "    layer_shape = layer.get_shape()\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    return layer_flat, num_features\n",
    "\n",
    "def new_fc_layer(input, num_inputs, num_outputs, use_relu=True): \n",
    "    weights = weight_variable([num_inputs, num_outputs])\n",
    "    biases = bias_variable([num_outputs])\n",
    " \n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    " \n",
    "    return layer\n",
    "\n",
    "# our network!!!\n",
    "\n",
    "# input data\n",
    "x = tf.placeholder(tf.float32, shape=[None, 28*28], name='input_data')\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "# correct labels\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10], name='correct_labels')\n",
    "\n",
    "# fist conv layer\n",
    "convlayer1, w1 = new_conv_layer(x_image, 1, 5, 32)\n",
    "# second conv layer\n",
    "convlayer2, w2 = new_conv_layer(convlayer1, 32, 5, 64)\n",
    "# flat layer\n",
    "flat_layer, num_features = flatten_layer(convlayer2)\n",
    "# fully connected layer\n",
    "fclayer = new_fc_layer(flat_layer, num_features, 1024)\n",
    "# DROPOUT\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "drop_layer = tf.nn.dropout(fclayer, keep_prob)\n",
    "# final layer\n",
    "W_f = weight_variable([1024, 10])\n",
    "b_f = bias_variable([10])\n",
    "y_f = tf.matmul(drop_layer, W_f) + b_f\n",
    "\n",
    "# loss\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_f))\n",
    "\n",
    "# train step\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "# accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y_f, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# init\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.250000\n",
      "step 100, training accuracy 0.750000\n",
      "step 200, training accuracy 0.937500\n",
      "step 300, training accuracy 0.875000\n",
      "step 400, training accuracy 0.937500\n",
      "step 500, training accuracy 0.812500\n",
      "step 600, training accuracy 0.875000\n",
      "step 700, training accuracy 1.000000\n",
      "step 800, training accuracy 0.937500\n",
      "step 900, training accuracy 0.875000\n",
      "step 1000, training accuracy 0.875000\n",
      "step 1100, training accuracy 0.875000\n",
      "step 1200, training accuracy 0.875000\n",
      "step 1300, training accuracy 1.000000\n",
      "step 1400, training accuracy 1.000000\n",
      "step 1500, training accuracy 0.875000\n",
      "step 1600, training accuracy 0.812500\n",
      "step 1700, training accuracy 0.937500\n",
      "step 1800, training accuracy 1.000000\n",
      "step 1900, training accuracy 1.000000\n",
      "step 2000, training accuracy 0.937500\n",
      "step 2100, training accuracy 0.937500\n",
      "step 2200, training accuracy 0.937500\n",
      "step 2300, training accuracy 1.000000\n",
      "step 2400, training accuracy 1.000000\n",
      "step 2500, training accuracy 1.000000\n",
      "step 2600, training accuracy 0.937500\n",
      "step 2700, training accuracy 1.000000\n",
      "step 2800, training accuracy 1.000000\n",
      "step 2900, training accuracy 1.000000\n",
      "Done!\n",
      "Evaluating...\n",
      "0: test accuracy 1.000000\n",
      "10: test accuracy 0.920000\n",
      "20: test accuracy 1.000000\n",
      "30: test accuracy 0.960000\n",
      "40: test accuracy 0.940000\n",
      "50: test accuracy 1.000000\n",
      "60: test accuracy 0.960000\n",
      "70: test accuracy 0.920000\n",
      "80: test accuracy 0.940000\n",
      "90: test accuracy 0.920000\n",
      "100: test accuracy 0.980000\n",
      "110: test accuracy 1.000000\n",
      "120: test accuracy 0.920000\n",
      "130: test accuracy 0.860000\n",
      "140: test accuracy 1.000000\n",
      "150: test accuracy 1.000000\n",
      "160: test accuracy 0.960000\n",
      "170: test accuracy 1.000000\n",
      "180: test accuracy 1.000000\n",
      "190: test accuracy 0.980000\n",
      "avg test accuracy: 0.970300001204\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3000\n",
    "batch_size = 16\n",
    "test_size = 10000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        if step % 100 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "                x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            print('step %d, training accuracy %f' %(step, train_accuracy))\n",
    "        \n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "    print 'Done!'\n",
    "    print 'Evaluating...'\n",
    "    \n",
    "    test_accuracy = 0.0\n",
    "    for i in xrange(test_size/50):\n",
    "        batch = mnist.test.next_batch(50)\n",
    "        acc = accuracy.eval(feed_dict={x: batch[0], y_: batch[1],\n",
    "                                       keep_prob: 1.0})\n",
    "        if i % 10 == 0:\n",
    "            print('%d: test accuracy %f' % (i, acc))\n",
    "        test_accuracy += acc\n",
    "    print 'avg test accuracy:', test_accuracy/(test_size/50.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering all the test data the result can be better. But my pc is poor and weak :( so I wasn't able to run it.\n",
    "\n",
    "I Hope you enjoyed the tutorial, see ya o/!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
